apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: from-beginning-with-filter-1
  namespace: kafka-poc-ns
  labels:
    strimzi.io/cluster: kafka-connect-poc-cluster
spec:
  class: "com.mongodb.kafka.connect.MongoSourceConnector"
  tasksMax: 1
  config:
    connection.uri: "mongodb://${file:/opt/kafka/external-configuration/mongo-credentials/mongo-credentials.properties:username}:${file:/opt/kafka/external-configuration/mongo-credentials/mongo-credentials.properties:password}@database.mongodb:27017"
    database: "poc_db"
    collection: "sequence_filter"
    copy.existing: true
    topic.namespace.map: "{\"*\": \"from_beginning_with_filter\"}"
    change.data.capture.handler: "com.mongodb.kafka.connect.sink.cdc.mongodb.ChangeStreamHandler"
    change.stream.full.document: "updateLookup"
# by default when string converter is not used then document is escaped by \ in kafka.
    key.converter: "org.apache.kafka.connect.storage.StringConverter"
    value.converter: "org.apache.kafka.connect.storage.StringConverter"
# to filter document where complete is true for existing documents.
    copy.existing.pipeline: "[{ \"$match\": { \"complete\": true } }]"
# to filter document where complete is true for newly arriving documents.
    pipeline: "[{ \"$match\": { \"fullDocument.complete\": true } }]"
# Error handling
    mongo.errors.tolerance: "all"
    mongo.errors.deadletterqueue.topic.name: "mongo_extract_errors"
    heartbeat.interval.ms: 30000